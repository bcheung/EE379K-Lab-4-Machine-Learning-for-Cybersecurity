{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4, Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "The goal of this exercise is to build a straightforward machine learning pipeline for a problem with more than two classes.  A lot of the data preprocessing has already been done, so the main focus of this exercise is to become familiar with loading data, training a model, doing inference, and analyzing the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "\n",
    "For example, here's the first couple rows of the dataset:\n",
    "\n",
    "| Source IP    |  Source Port |  Destination IP   |  Destination Port |  Protocol |  Flow Duration |  Flow Bytes/s |  Flow Packets/s |  Flow IAT Mean |  Flow IAT Std |  Flow IAT Max |  Flow IAT Min | Fwd IAT Mean |  Fwd IAT Std |  Fwd IAT Max |  Fwd IAT Min | Bwd IAT Mean |  Bwd IAT Std |  Bwd IAT Max |  Bwd IAT Min | Active Mean |  Active Std |  Active Max |  Active Min | Idle Mean |  Idle Std |  Idle Max |  Idle Min | label |\n",
    "|--------------|--------------|-------------------|-------------------|-----------|----------------|---------------|-----------------|----------------|---------------|---------------|---------------|--------------|--------------|--------------|--------------|--------------|--------------|--------------|--------------|-------------|-------------|-------------|-------------|-----------|-----------|-----------|-----------|-------|\n",
    "| 10\\.0\\.2\\.15 | 57188        | 82\\.161\\.239\\.177 | 110               | 6         | 7248168        | 21126\\.02798  | 29\\.11080428    | 34515\\.08571   | 273869\\.2625  | 3897923       | 5             | 89483\\.55556 | 437167\\.5917 | 3898126      | 29           | 56614\\.03906 | 349855\\.1098 | 3898131      | 7            | 0           | 0           | 0           | 0           | 0         | 0         | 0         | 0         | AUDIO |\n",
    "| 10\\.0\\.2\\.15 | 57188        | 82\\.161\\.239\\.177 | 110               | 6         | 5157723        | 1052\\.790156  | 3\\.683796125    | 286540\\.1667   | 878838\\.5256  | 3743359       | 135           | 644715\\.375  | 1272066\\.058 | 3743562      | 509          | 568901\\.6667 | 1209110\\.287 | 3743573      | 451          | 0           | 0           | 0           | 0           | 0         | 0         | 0         | 0         | AUDIO |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import CSV data as a Pandas dataframe\n",
    "# The data is in 'data/exercise2/TOR_TimeBasedFeatures-10s-Layer2.csv'\n",
    "\n",
    "# CODE HERE\n",
    "\n",
    "tor_df = pd.read_csv('data/exercise2/TOR_TimeBasedFeatures-10s-Layer2.csv', delimiter=' *, *', engine='python')\n",
    "# Create data and labels that can be used by sklearn's 'train_test_split'\n",
    "# Create the labels\n",
    "\n",
    "# CODE HERE\n",
    "labels = tor_df['label']\n",
    "\n",
    "# Create the data\n",
    "# -Keep just the numeric features (i.e., those features between 'Flow Duration' and 'Idle Min')\n",
    "# -Make sure not to keep the labels\n",
    "\n",
    "# CODE HERE\n",
    "data = tor_df.loc[:, 'Flow Duration':'Idle Min']\n",
    "\n",
    "# You should now have data and labels that can be used by sklearn's 'train_test_split'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a single train/test split for experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly pick 50% of the data for the training set, and keep the remaining 50% for the test set\n",
    "# Use sklearn's 'train_test_split'\n",
    "# CODE HERE\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(data, labels, test_size=0.5);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bcheung/Documents/SoftwareProjects/UT/EE379K/lab4/venv/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Train a random forest classifier using default hyperparameters\n",
    "# Hint: Not counting any import statements, this can be done in a single line of code\n",
    "# CODE HERE\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "model = rf.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the classifier on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 274   73    4    5    2    0    4    4]\n",
      " [  67  611   31   11   14    1   58    2]\n",
      " [  11   72   57    1    1    1    8    3]\n",
      " [   5   30    2  348    5    1   17    1]\n",
      " [   3   45    4    7   57    0   19    1]\n",
      " [   6    6    1    0    1  536    3    2]\n",
      " [  22   91    8   25   11   12  268    4]\n",
      " [   8   21    8    6    2    4    3 1114]] \n",
      "\n",
      "Confusion Matrix Percentages with Labels:\n",
      "Predicted          AUDIO   BROWSING       CHAT  FILE-TRANSFER       MAIL  \\\n",
      "True                                                                       \n",
      "AUDIO          69.191919   7.692308   3.478261       1.240695   2.150538   \n",
      "BROWSING       16.919192  64.383562  26.956522       2.729529  15.053763   \n",
      "CHAT            2.777778   7.586934  49.565217       0.248139   1.075269   \n",
      "FILE-TRANSFER   1.262626   3.161222   1.739130      86.352357   5.376344   \n",
      "MAIL            0.757576   4.741834   3.478261       1.736973  61.290323   \n",
      "P2P             1.515152   0.632244   0.869565       0.000000   1.075269   \n",
      "VIDEO           5.555556   9.589041   6.956522       6.203474  11.827957   \n",
      "VOIP            2.020202   2.212856   6.956522       1.488834   2.150538   \n",
      "\n",
      "Predicted            P2P      VIDEO       VOIP  \n",
      "True                                            \n",
      "AUDIO           0.000000   1.052632   0.353669  \n",
      "BROWSING        0.180180  15.263158   0.176835  \n",
      "CHAT            0.180180   2.105263   0.265252  \n",
      "FILE-TRANSFER   0.180180   4.473684   0.088417  \n",
      "MAIL            0.000000   5.000000   0.088417  \n",
      "P2P            96.576577   0.789474   0.176835  \n",
      "VIDEO           2.162162  70.526316   0.353669  \n",
      "VOIP            0.720721   0.789474  98.496905   \n",
      "\n",
      "accuracy = 0.8117851815017404\n"
     ]
    }
   ],
   "source": [
    "# Predict the labels on the test set\n",
    "\n",
    "# CODE HERE\n",
    "\n",
    "pred_labels = model.predict(test_data)\n",
    "\n",
    "# Use accuracy and a confusion matrix to measure performance\n",
    "# Hint: Use sklearn's built-in metrics\n",
    "\n",
    "# CODE HERE\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "def print_results(test_labels, pred_labels):\n",
    "    \n",
    "    print('Confusion Matrix:')\n",
    "    conf_mat = confusion_matrix(test_labels, pred_labels)\n",
    "    print(conf_mat, '\\n')\n",
    "    print('Confusion Matrix Percentages with Labels:')\n",
    "    print(pd.crosstab(test_labels, pred_labels, rownames=['True'], colnames=['Predicted']).apply(lambda r: 100.0 * r/r.sum()), '\\n')\n",
    "\n",
    "    accuracy = accuracy_score(test_labels, pred_labels)\n",
    "    print('accuracy =', accuracy)\n",
    "    \n",
    "print_results(test_labels, pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Important Features:\n",
      "['Feature: Flow Bytes/s         Importance: 0.10310492081883266',\n",
      " 'Feature: Flow IAT Mean        Importance: 0.0876804243452377',\n",
      " 'Feature: Fwd IAT Min          Importance: 0.08213329271746557',\n",
      " 'Feature: Bwd IAT Max          Importance: 0.08101557963743383',\n",
      " 'Feature: Fwd IAT Std          Importance: 0.07260585692758294',\n",
      " 'Feature: Bwd IAT Mean         Importance: 0.06855163514908563',\n",
      " 'Feature: Flow Duration        Importance: 0.06477037590870895',\n",
      " 'Feature: Fwd IAT Max          Importance: 0.062401548688102944',\n",
      " 'Feature: Flow Packets/s       Importance: 0.05992160889734805',\n",
      " 'Feature: Fwd IAT Mean         Importance: 0.05829874301265863',\n",
      " 'Feature: Flow IAT Std         Importance: 0.0539892778004704',\n",
      " 'Feature: Bwd IAT Min          Importance: 0.053109622896184365',\n",
      " 'Feature: Flow IAT Max         Importance: 0.05101987425716844',\n",
      " 'Feature: Flow IAT Min         Importance: 0.04677616471049703',\n",
      " 'Feature: Bwd IAT Std          Importance: 0.03408307084838396',\n",
      " 'Feature: Active Mean          Importance: 0.004613553532152716',\n",
      " 'Feature: Active Min           Importance: 0.004511335767928641',\n",
      " 'Feature: Active Max           Importance: 0.003615768042074981',\n",
      " 'Feature: Idle Min             Importance: 0.0034512158824382406',\n",
      " 'Feature: Idle Mean            Importance: 0.0025117258016802485',\n",
      " 'Feature: Idle Max             Importance: 0.0018344043585641742',\n",
      " 'Feature: Active Std           Importance: 0.0',\n",
      " 'Feature: Idle Std             Importance: 0.0']\n"
     ]
    }
   ],
   "source": [
    "# Determine important features\n",
    "\n",
    "# CODE HERE\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "feature_importances = model.feature_importances_\n",
    "\n",
    "print('Important Features:')\n",
    "important_feats = sorted(list(zip(test_data.columns, feature_importances)), key=lambda feat: feat[1], reverse=True)\n",
    "pprint(['Feature: {:20} Importance: {}'.format(*pair) for pair in important_feats])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions:\n",
    "\n",
    "1) What is the overall accuracy using the default parameters?  \n",
    "\n",
    "Accuracy: 0.7993\n",
    "\n",
    "2) What is the confusion matrix for the tested approach?  What are the classes where the model performs well?  What are the classes where the model performs poorly?\n",
    "\n",
    "Confusion Matrix:\n",
    "\n",
    "```\n",
    "[[ 259   92    3    2    3    2   13    1]\n",
    " [  60  622   29    2   17    2   63    1]\n",
    " [   3   99   45    2    1    0    5    2]\n",
    " [   5   35    1  379   10    0   17    4]\n",
    " [   5   56    6   11   52    0   18    0]\n",
    " [   6    8    1    1    0  519    7    1]\n",
    " [  30   93    5   19   12   11  259    3]\n",
    " [   4   23    5    1    0    3    4 1080]]\n",
    " ```\n",
    " \n",
    " The model performs well on FILE-TRANSFER, P2P, and VOIP.\n",
    " The model performs poorly on AUDIO, BROWSING, CHAT, MAIL, and VIDEO.\n",
    " \n",
    "3) What are the top 5 most important features?\n",
    "\n",
    "1. Flow Bytes/s\n",
    "2. Flow IAT Max\n",
    "3. Flow IAT Mean\n",
    "4. Bwd IAT Min\n",
    "5. Bwd IAT Max\n",
    "\n",
    "4) What hyperparameters could you tune in the random forest to improve performance? What is the best accuracy you can attain?\n",
    "\n",
    "<!-- https://medium.com/all-things-ai/in-depth-parameter-tuning-for-random-forest-d67bb7e920d -->\n",
    "<!-- https://medium.com/@taplapinger/tuning-a-random-forest-classifier-1b252d1dde92 -->\n",
    "<!-- https://www.analyticsvidhya.com/blog/2015/06/tuning-random-forest-model/ -->\n",
    "\n",
    "n_estimators=1000, max_features=10\n",
    "Accuracy: 0.8352\n",
    "(Tuned model below)\n",
    "\n",
    "5) Bonus: How would you improve the pipeline above to automatically tune the hyperparameters?  How would you improve the pipeline to use multiple train/test splits?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': True,\n",
      " 'class_weight': None,\n",
      " 'criterion': 'gini',\n",
      " 'max_depth': None,\n",
      " 'max_features': 'auto',\n",
      " 'max_leaf_nodes': None,\n",
      " 'min_impurity_decrease': 0.0,\n",
      " 'min_impurity_split': None,\n",
      " 'min_samples_leaf': 1,\n",
      " 'min_samples_split': 2,\n",
      " 'min_weight_fraction_leaf': 0.0,\n",
      " 'n_estimators': 10,\n",
      " 'n_jobs': None,\n",
      " 'oob_score': False,\n",
      " 'random_state': None,\n",
      " 'verbose': 0,\n",
      " 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "pprint(rf.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 281   61    3    4    2    1   11    3]\n",
      " [  60  647   22    2    7    1   54    2]\n",
      " [   7   78   53    1    0    1    9    5]\n",
      " [   6   26    2  363    2    0    8    2]\n",
      " [   5   49    3    8   50    0   20    1]\n",
      " [   5    4    2    0    0  536    6    2]\n",
      " [  21   71    4   18    5    8  310    4]\n",
      " [   4   19    8    4    1    3    8 1119]] \n",
      "\n",
      "Confusion Matrix Percentages with Labels:\n",
      "Predicted          AUDIO   BROWSING       CHAT  FILE-TRANSFER       MAIL  \\\n",
      "True                                                                       \n",
      "AUDIO          72.236504   6.387435   3.092784           1.00   2.985075   \n",
      "BROWSING       15.424165  67.748691  22.680412           0.50  10.447761   \n",
      "CHAT            1.799486   8.167539  54.639175           0.25   0.000000   \n",
      "FILE-TRANSFER   1.542416   2.722513   2.061856          90.75   2.985075   \n",
      "MAIL            1.285347   5.130890   3.092784           2.00  74.626866   \n",
      "P2P             1.285347   0.418848   2.061856           0.00   0.000000   \n",
      "VIDEO           5.398458   7.434555   4.123711           4.50   7.462687   \n",
      "VOIP            1.028278   1.989529   8.247423           1.00   1.492537   \n",
      "\n",
      "Predicted            P2P      VIDEO       VOIP  \n",
      "True                                            \n",
      "AUDIO           0.181818   2.582160   0.263620  \n",
      "BROWSING        0.181818  12.676056   0.175747  \n",
      "CHAT            0.181818   2.112676   0.439367  \n",
      "FILE-TRANSFER   0.000000   1.877934   0.175747  \n",
      "MAIL            0.000000   4.694836   0.087873  \n",
      "P2P            97.454545   1.408451   0.175747  \n",
      "VIDEO           1.454545  72.769953   0.351494  \n",
      "VOIP            0.545455   1.877934  98.330404   \n",
      "\n",
      "accuracy = 0.8351566384883142\n"
     ]
    }
   ],
   "source": [
    "tuned_rf = RandomForestClassifier(n_estimators=1000, max_features=10, random_state=0)\n",
    "tuned_model = tuned_rf.fit(train_data, train_labels)\n",
    "tuned_pred_labels = tuned_model.predict(test_data)\n",
    "print_results(test_labels, tuned_pred_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
