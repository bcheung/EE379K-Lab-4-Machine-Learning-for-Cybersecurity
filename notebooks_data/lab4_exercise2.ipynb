{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4, Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "The goal of this exercise is to build a straightforward machine learning pipeline for a problem with more than two classes.  A lot of the data preprocessing has already been done, so the main focus of this exercise is to become familiar with loading data, training a model, doing inference, and analyzing the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "\n",
    "For example, here's the first couple rows of the dataset:\n",
    "\n",
    "| Source IP    |  Source Port |  Destination IP   |  Destination Port |  Protocol |  Flow Duration |  Flow Bytes/s |  Flow Packets/s |  Flow IAT Mean |  Flow IAT Std |  Flow IAT Max |  Flow IAT Min | Fwd IAT Mean |  Fwd IAT Std |  Fwd IAT Max |  Fwd IAT Min | Bwd IAT Mean |  Bwd IAT Std |  Bwd IAT Max |  Bwd IAT Min | Active Mean |  Active Std |  Active Max |  Active Min | Idle Mean |  Idle Std |  Idle Max |  Idle Min | label |\n",
    "|--------------|--------------|-------------------|-------------------|-----------|----------------|---------------|-----------------|----------------|---------------|---------------|---------------|--------------|--------------|--------------|--------------|--------------|--------------|--------------|--------------|-------------|-------------|-------------|-------------|-----------|-----------|-----------|-----------|-------|\n",
    "| 10\\.0\\.2\\.15 | 57188        | 82\\.161\\.239\\.177 | 110               | 6         | 7248168        | 21126\\.02798  | 29\\.11080428    | 34515\\.08571   | 273869\\.2625  | 3897923       | 5             | 89483\\.55556 | 437167\\.5917 | 3898126      | 29           | 56614\\.03906 | 349855\\.1098 | 3898131      | 7            | 0           | 0           | 0           | 0           | 0         | 0         | 0         | 0         | AUDIO |\n",
    "| 10\\.0\\.2\\.15 | 57188        | 82\\.161\\.239\\.177 | 110               | 6         | 5157723        | 1052\\.790156  | 3\\.683796125    | 286540\\.1667   | 878838\\.5256  | 3743359       | 135           | 644715\\.375  | 1272066\\.058 | 3743562      | 509          | 568901\\.6667 | 1209110\\.287 | 3743573      | 451          | 0           | 0           | 0           | 0           | 0         | 0         | 0         | 0         | AUDIO |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import CSV data as a Pandas dataframe\n",
    "# The data is in 'data/exercise2/TOR_TimeBasedFeatures-10s-Layer2.csv'\n",
    "\n",
    "# CODE HERE\n",
    "\n",
    "# Create data and labels that can be used by sklearn's 'train_test_split'\n",
    "# Create the labels\n",
    "\n",
    "# CODE HERE\n",
    "\n",
    "# Create the data\n",
    "# -Keep just the numeric features (i.e., those features between 'Flow Duration' and 'Idle Min')\n",
    "# -Make sure not to keep the labels\n",
    "\n",
    "# CODE HERE\n",
    "\n",
    "# You should now have data and labels that can be used by sklearn's 'train_test_split'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a single train/test split for experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly pick 50% of the data for the training set, and keep the remaining 50% for the test set\n",
    "# Use sklearn's 'train_test_split'\n",
    "# CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a random forest classifier using default hyperparameters\n",
    "# Hint: Not counting any import statements, this can be done in a single line of code\n",
    "# CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the classifier on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the labels on the test set\n",
    "\n",
    "# CODE HERE\n",
    "\n",
    "# Use accuracy and a confusion matrix to measure performance\n",
    "# Hint: Use sklearn's built-in metrics\n",
    "\n",
    "# CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine important features\n",
    "\n",
    "# CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions:\n",
    "\n",
    "1) What is the overall accuracy using the default parameters?  \n",
    "\n",
    "2) What is the confusion matrix for the tested approach?  What are the classes where the model performs well?  What are the classes where the model performs poorly?\n",
    "\n",
    "3) What are the top 5 most important features?\n",
    "\n",
    "4) What hyperparameters could you tune in the random forest to improve performance? What is the best accuracy you can attain?\n",
    "\n",
    "5) Bonus: How would you improve the pipeline above to automatically tune the hyperparameters?  How would you improve the pipeline to use multiple train/test splits?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
